{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as ureq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as td\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Read the old file from the share folder\n",
    "file_name_offline = \"/Users/Kumaran/Desktop/Sales.xlsx\"\n",
    "df_old_sales = pd.read_excel(file_name_offline)\n",
    "\n",
    "# Log file\n",
    "name_n_sales_offline = '/Users/Kumaran/Desktop/n_sales_offline.csv'\n",
    "\n",
    "\n",
    "# Build up the start date as today and end date as one year from today\n",
    "st_date = dt.strftime(dt.today(), '%Y-%m-%d')\n",
    "ed_date = dt.strftime(dt.today() + td(days=365), '%Y-%m-%d')\n",
    "\n",
    "url_template = \"http://www.christies.com/Calendar?startdate={}&enddate={}\".format(st_date,ed_date)\n",
    "response = ureq(url_template)\n",
    "\n",
    "contents = response.read()\n",
    "parsed_html = soup(contents,\"html.parser\")\n",
    "containers = parsed_html.findAll('div', {'class': 'col-xs-12 col-sm-12 col-md-12 col-lg-12 sale--items--item no-padding'})\n",
    "\n",
    "# This function converts the string date to required format YYYYMMDD\n",
    "def sale_date_parser(str_date):\n",
    "    splt_date = str_date.split('-')\n",
    "    if len(splt_date) < 2:                                              # When there is only start date\n",
    "        lv_date = str_date\n",
    "    else:                                                               # When there is both start date and end date\n",
    "        lv_s_date = splt_date[0].strip()\n",
    "        lv_date = splt_date[1].strip()\n",
    "\n",
    "    sale_date_parser = dt.strptime(str(dt.today().year) + ' ' + lv_date, '%Y %d %b')\n",
    "\n",
    "    lv_month = sale_date_parser.strftime('%m')\n",
    "    lv_day = sale_date_parser.strftime('%d')\n",
    "\n",
    "    if len(splt_date) < 2:\n",
    "        parsed_st_date = str(sale_date_parser.year) + lv_month + lv_day\n",
    "        parsed_ed_date = parsed_st_date\n",
    "    else:\n",
    "        parsed_ed_date = str(sale_date_parser.year) + lv_month + lv_day\n",
    "        if len(lv_s_date) == 1:                                          #'1 - 12 Jan'\n",
    "            st_dat = '0' + splt_date[0].strip()[:1]\n",
    "        elif len(lv_s_date) > 2:                                         #'19 Feb - 1 Mar'\n",
    "            st_dat1 = dt.strptime(str(dt.today().year) + ' ' + lv_s_date, '%Y %d %b')\n",
    "            st_dat = str(st_dat1.strftime('%d'))\n",
    "            lv_month = str(st_dat1.strftime('%m'))\n",
    "        else:\n",
    "            st_dat = splt_date[0].strip()[:2]                            #'16 - 24 Jan'\n",
    "        parsed_st_date = str(sale_date_parser.year) + lv_month + st_dat\n",
    "    return parsed_st_date,parsed_ed_date\n",
    "\n",
    "\n",
    "# with open(\"/Users/Kumaran/Desktop/Christie's.csv\", 'w') as file:\n",
    "header = \"SaleNumber,SaleText,SaleLocation,Sale_url,SaleDate,StartDate,EndDate,SaleID\\n\"\n",
    "# file.write(header)\n",
    "\n",
    "# df_header = [\"SaleNumber\", \"SaleText\", \"SaleLocation\", \"Sale_url\", \"SaleDate\", \"StartDate\", \"EndDate\", \"SaleID\"]\n",
    "df_header = [\"sale_no\", \"sale_loc\", \"url\", \"start\", \"end\", \"sale_id\"]\n",
    "df_incmg_sales = pd.DataFrame(columns=df_header)\n",
    "incmg_list = []\n",
    "tomw_list= []\n",
    "tomorrow = (dt.today() + td(1)).strftime(\"%Y%m%d\")\n",
    "\n",
    "for container in containers:\n",
    "    Sale_number = int(container.find('span',{'class':'image-description--sale-number hidden-xs hidden-sm p--primary_large'}).getText())\n",
    "    # Sale_number = container.span.getText()[7:]\n",
    "    Sale_text = container.h6.a.getText().replace(',',' ')\n",
    "    Sale_location = container.find('span',{'class':'image-description--location hidden-xs hidden-sm p--primary_large'}).getText()\n",
    "    Sale_date = container.h4.getText()\n",
    "    Start_date, End_date = sale_date_parser(Sale_date)\n",
    "    Sale_url = container.find('a',{'class':'image-hyperlink'}).get('href')\n",
    "    s_indx = Sale_url.find('SaleID=')+7\n",
    "    Sale_id = Sale_url[s_indx:s_indx+5]\n",
    "\n",
    "    # incmg_list.append([Sale_number,Sale_text,Sale_location,Sale_url, Sale_date, Start_date, End_date, Sale_id])\n",
    "    incmg_list.append([Sale_number, Sale_location, Sale_url, Start_date, End_date, Sale_id])\n",
    "\n",
    "# Capture tomorrow's sale separately\n",
    "    if Start_date == tomorrow:\n",
    "        # tomw_list.append([Sale_number,Sale_text,Sale_location,Sale_url, Sale_date, Start_date, End_date, Sale_id])\n",
    "        tomw_list.append([Sale_number, Sale_location, Sale_url, Start_date, End_date, Sale_id])\n",
    "\n",
    "\n",
    "    # print(Sale_number, '|', Sale_text, '|', Sale_location, '|', Sale_url, '|', Sale_date, '|', Start_date, '|',End_date, '|', Sale_id)\n",
    "    # file.write(Sale_number + ',' + Sale_text + ',' + Sale_location + ',' + Sale_url + ',' + Sale_date + ',' + Start_date + ',' + End_date + ',' + Sale_id + '\\n')\n",
    "\n",
    "# Append the incoming sales which was extracted\n",
    "dff = pd.DataFrame(incmg_list,columns=df_header)                    # Append the output list to a temp DF\n",
    "df_incmg_sales = pd.concat([dff])                                   # Append the temp to main DF\n",
    "# df_new_sales.drop(['SaleText','SaleDate'],axis=1,inplace=True)\n",
    "\n",
    "# capture tomorrow sales\n",
    "dff = pd.DataFrame(tomw_list,columns=df_header)                    # Append the output list to a temp DF\n",
    "df_tomorrow_sales = pd.concat([dff])                               # Append the temp to main DF\n",
    "# df_tomorrow_sales.drop(['SaleText', 'SaleDate'], axis=1, inplace=True) # For now just drop these\n",
    "\n",
    "\n",
    "# Check and update the new records from new dataframe onto the old dataframe\n",
    "logs =[]\n",
    "df_unique_new = pd.DataFrame(columns=df_header, index=range(1))\n",
    "new_sales = pd.DataFrame(columns=df_header, index=range(1))\n",
    "\n",
    "logs.append(\"Following New Sales are being Loaded\")\n",
    "for index, row in df_incmg_sales.iterrows():\n",
    "# Only the sale that are not online.\n",
    "    if row.sale_loc != 'Online':\n",
    "# Check if the sale is already in the table\n",
    "        if len(df_old_sales.loc[df_old_sales['sale_no'] == row.sale_no].index) == 0:\n",
    "# if not add it.\n",
    "            for a in range(1):\n",
    "                df_unique_new.loc[a].sale_no  = row.sale_no\n",
    "                df_unique_new.loc[a].sale_loc = row.sale_loc\n",
    "                df_unique_new.loc[a].url      = row.url\n",
    "                df_unique_new.loc[a].start    = row.start\n",
    "                df_unique_new.loc[a].end      = row.end\n",
    "                df_unique_new.loc[a].sale_id  = row.sale_id\n",
    "                df_old_sales = df_old_sales.append(df_unique_new, ignore_index=True)\n",
    "                logs.append(str(row.sale_no) + \"-\" + row.sale_loc)\n",
    "                print(str(row.sale_no) + \"-\" + row.sale_loc)\n",
    "# Also create a file with the new sales separately\n",
    "                new_sales = new_sales.append(df_unique_new, ignore_index=True)\n",
    "\n",
    "# Now dump the  dataframe data to 'Old sales list'\n",
    "df_old_sales.to_excel(file_name_offline, header=True, index=False)\n",
    "\n",
    "# Output the log file from the Dataframe\n",
    "logs_out = pd.DataFrame(logs, columns=['log'])\n",
    "logs_out.to_csv(name_n_sales_offline, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
